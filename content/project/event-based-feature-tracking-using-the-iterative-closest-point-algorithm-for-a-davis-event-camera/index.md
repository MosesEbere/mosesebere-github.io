---
title: " Event-Based Feature Tracking Using the Iterative Closest Point
  Algorithm (for a DAVIS event camera)"
date: 2023-09-30T13:40:16.887Z
summary: F﻿eature Tracking with Events
draft: false
featured: false
authors:
  - Moses Ebere
  - Joseph Adeola
  - Preeti Verma
tags:
  - Neuromorphic Vision
links:
  - icon: video
    icon_pack: fas
    name: Event Tracker Video
    url: https://drive.google.com/file/d/1-G5hqHL8huC9X2n_K4D6nK4Eiw-SMkj_/view?usp=sharing
  - icon: video
    icon_pack: fas
    name: GroundTruth Video
    url: https://drive.google.com/file/d/1lrb0gsTHLV2ilZY8J5d77WqLP4vHVgNf/view?usp=sharing
  - icon: file-powerpoint
    icon_pack: fas
    name: Slides
    url: https://drive.google.com/file/d/1hdV3W1TY7xFmR7wgNJ0O0OogE2QmWqb2/view?usp=sharing
  - icon: book
    icon_pack: fas
    name: Report
    url: https://drive.google.com/file/d/1c5LUlqVDj0flfkdqguSWeiyO6UckfFRC/view?usp=sharing
image:
  filename: featured.jpg
  focal_point: Smart
  preview_only: false
  caption: Event-based Feature Tracking
---
In this project, we implement a feature detection and tracking algorithm for an event-based vision camera: the Dynamic and Active-pixel Vision Sensor (DAVIS) event camera.

\
Event cameras offer advantages like high temporal resolution, minimal latency, and extended dynamic range compared to traditional cameras; however, specialized algorithms are required to leverage the asynchronous data generated by such cameras. Therefore, we took on this feature detection and tracking project. 

The ICP-based tracker is initialized with edge and corner features from the grayscale images of the DAVIS camera using OpenCV. A collection of interest points is generated by drawing bounding boxes around each corner feature. For every 'n' events generated by the camera, an event image is created by binning these 'n' events. Using the aforementioned bounding boxes, a collection of event interest points is also obtained. With the ICP algorithm, feature matching is done for each set of corresponding points in both collections, and the resulting displacement is used to transform the original features and their bounding boxes. The process continues iteratively for the entire sequence available. 

T﻿o mitigate the inevitable loss of features, a feature reinitialization step is also included in the pipeline. With the above, feature detection and tracking by way of events is realized. One key limitation of this inherent loss of the exact asynchronous nature of the event since a group of events are binned into an event image.
